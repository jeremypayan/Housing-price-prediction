{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle competition : Housing Price prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Objective </b>: Predict house price \n",
    "    \n",
    "<b>Problem type</b> : Regression \n",
    "\n",
    "<b>Data </b>: described in Data/data_description.txt \n",
    "    \n",
    "<b>Modelisation </b>: \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation 1 : Testing different models with a selection of features (only non null values)\n",
    "\n",
    "We are choosing some numerical features to train a first model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get input data \n",
    "X_full = pd.read_csv('Data/train.csv', sep=',', index_col='Id')\n",
    "X_full_test = pd.read_csv('Data/test.csv', sep=',', index_col='Id')\n",
    "\n",
    "# Predictors\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = X_full[features].copy()\n",
    "X_test = X_full_test[features].copy()\n",
    "\n",
    "# Target\n",
    "y = X_full.SalePrice\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Getting mae performance for testing different models\n",
    "def get_mae(X_train, y_train, X_val, y_val, model):\n",
    "    '''Function that computes the mae perfomance for a given model given in input\n",
    "    ----------\n",
    "    Returns : \n",
    "        error (float) : MAE value given the input model and X, y datasets\n",
    "    -----------\n",
    "    Agurments :\n",
    "        X_train, X_test (dataframes) : Input dataframes for test and train sets\n",
    "        y_train, y_test (Series)     : Series of labels for test and train sets\n",
    "    \n",
    "    '''\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_val)\n",
    "    error = mean_absolute_error(predictions, y_val)\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing different models \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the models\n",
    "model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "model_2 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model_3 = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0)\n",
    "model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\n",
    "model_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4, model_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score model_1 :  24015.492818003917\n",
      "Score model_2 :  23740.979228636657\n",
      "Score model_3 :  23528.78421232877\n",
      "Score model_4 :  23996.676789668687\n",
      "Score model_5 :  23706.672864217904\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(models) :\n",
    "    score = get_mae(X_train, y_train, X_val, y_val, model=model)\n",
    "    print('Score model_{} : '.format(i+1), score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model 3 is the most performant in this first try ! This is the one we'll use ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submitting results for model 3 and selected features \n",
    "\n",
    "# Fit the model to the training data\n",
    "model_3.fit(X_train, y_train)\n",
    "\n",
    "# Generate test predictions\n",
    "preds_test = model_3.predict(X_test)\n",
    "\n",
    "# Save predictions in format used for competition scoring\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation 2 : Handling missing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get input data \n",
    "X_full = pd.read_csv('Data/train.csv', sep=',', index_col='Id')\n",
    "X_full_test = pd.read_csv('Data/test.csv', sep=',', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "\n",
    "# Separate target from predictors\n",
    "y = X_full.SalePrice\n",
    "X = X_full.drop('SalePrice', axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "X = X_full.select_dtypes(exclude=['object'])\n",
    "X_test = X_full_test.select_dtypes(exclude=['object'])\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test.columns) == len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Missing data  exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size 1460\n",
      "Columns with missing values :  ['LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
      "Missing values by columns LotFrontage      259\n",
      "Alley           1369\n",
      "MasVnrType         8\n",
      "MasVnrArea         8\n",
      "BsmtQual          37\n",
      "BsmtCond          37\n",
      "BsmtExposure      38\n",
      "BsmtFinType1      37\n",
      "BsmtFinType2      38\n",
      "Electrical         1\n",
      "FireplaceQu      690\n",
      "GarageType        81\n",
      "GarageYrBlt       81\n",
      "GarageFinish      81\n",
      "GarageQual        81\n",
      "GarageCond        81\n",
      "PoolQC          1453\n",
      "Fence           1179\n",
      "MiscFeature     1406\n",
      "dtype: int64 Total number of missing entries 6965\n"
     ]
    }
   ],
   "source": [
    "# Handling missing data \n",
    "\n",
    "# Number of lines \n",
    "print('total size', len(X_full))\n",
    "\n",
    "# Columns with missing values \n",
    "cols_to_drop = [col for col in X_train.columns if X_train[col].isnull().sum() > 0 ]\n",
    "print('Columns with missing values : ', cols_missing_values)\n",
    "\n",
    "\n",
    "# Number of missing values \n",
    "S_missing_values = X_full.isnull().sum()\n",
    "print('Missing values by columns', S_missing_values[S_missing_values > 0], 'Total number of missing entries', S_missing_values.sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 1 : Removing columns with missing data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17895.090633561642\n"
     ]
    }
   ],
   "source": [
    "# Dropping columns with missing values \n",
    "\n",
    "reduced_X_train = X_train.drop(cols_to_drop, axis=1)\n",
    "reduced_X_val = X_val.drop(cols_to_drop, axis=1)\n",
    "\n",
    "\n",
    "print(get_mae(X_train=reduced_X_train, y_train=y_train,\n",
    "                    X_val=reduced_X_val, y_val=y_val, model=model_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 2 : Imputing missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18093.391643835614\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_imputer = SimpleImputer(strategy='median')\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_val = pd.DataFrame(my_imputer.transform(X_val))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_val.columns = X_val.columns\n",
    "\n",
    "print(get_mae(X_train=imputed_X_train, y_train=y_train,\n",
    "                    X_val=imputed_X_val, y_val=y_val, model=model_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two strategies have almost the same results ! We choose to apply the imputation method. We see that the score have been increased ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing submission\n",
    "\n",
    "# Preparing data : handling missing data \n",
    "\n",
    "# Fit the model to the training data\n",
    "model_3.fit(imputed_X_train, y_train)\n",
    "\n",
    "# Imputing on missing values for X_test\n",
    "imputed_X_test = pd.DataFrame(my_imputer.fit_transform(X_test))\n",
    "imputed_X_test.columns = X_test.columns\n",
    "\n",
    "# Generate test predictions\n",
    "preds_test = model_3.predict(imputed_X_test)\n",
    "\n",
    "# Save predictions in format used for competition scoring\n",
    "output = pd.DataFrame({'Id': imputed_X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(output) == 1459 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation 3 : Handling categorical variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data : keeping categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get input data \n",
    "X_full = pd.read_csv('Data/train.csv', sep=',', index_col='Id')\n",
    "X_test = pd.read_csv('Data/test.csv', sep=',', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "\n",
    "# Separate target from predictors\n",
    "y = X_full.SalePrice\n",
    "X = X_full.drop('SalePrice', axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8,\n",
    "                                                 test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Removing columns that are in train set but not into test set \n",
    "\n",
    "print(len(X_train.columns) == len(X_test.columns)) # To test every time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train.columns) == len(X_val.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring categorical features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Alley', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('GarageFinish', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('PoolQC', 3),\n",
       " ('MiscFeature', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('MasVnrType', 4),\n",
       " ('ExterQual', 4),\n",
       " ('BsmtQual', 4),\n",
       " ('BsmtCond', 4),\n",
       " ('BsmtExposure', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('Fence', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Electrical', 5),\n",
       " ('FireplaceQu', 5),\n",
       " ('GarageQual', 5),\n",
       " ('GarageCond', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('BsmtFinType1', 6),\n",
       " ('BsmtFinType2', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('GarageType', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical columns\n",
    "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "# Cardinality of categorical features \n",
    "categorical_cardinality = list(map(lambda col : X_train[col].nunique(),categorical_cols))\n",
    "d = dict(zip(categorical_cols, categorical_cardinality))\n",
    "sorted(d.items(), key=lambda x : x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 1 : Dropping categorical features + Imputation on null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18093.391643835614\n"
     ]
    }
   ],
   "source": [
    "# Dropping categorical feaures \n",
    "reduced_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "reduced_X_val = X_val.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Imputing on missing values \n",
    "my_imputer = SimpleImputer(strategy='median')\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(reduced_X_train))\n",
    "imputed_X_val = pd.DataFrame(my_imputer.transform(reduced_X_val))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = reduced_X_train.columns\n",
    "imputed_X_val.columns = reduced_X_val.columns\n",
    "\n",
    "# Getting MAE performance \n",
    "print(get_mae(X_train=imputed_X_train, y_train=y_train,\n",
    "                    X_val=imputed_X_val, y_val=y_val, model=model_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 2 : Label encoding + imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17786.409109589044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Categorical columns\n",
    "obj_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "# Dropping categorical values available into X_val but unavailable into X_train\n",
    "good_label_cols = [col for col in X_train.columns if set(X_train[col]) == set(X_val[col])]\n",
    "bad_label_cols = list(set(obj_cols) - set(good_label_cols))\n",
    "\n",
    "X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "X_val = X_val.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Dropping categorical columns with empty values \n",
    "empty_label_cols = [col for col in good_label_cols if X_train[col].isnull().sum() > 0]\n",
    "label_X_train = X_train.drop(empty_label_cols, axis=1)\n",
    "label_X_val = X_val.drop(empty_label_cols, axis=1)\n",
    "\n",
    "label_cols = list(set(good_label_cols) - set(empty_label_cols))\n",
    "\n",
    "# Encoding features \n",
    "label_encoder = LabelEncoder()\n",
    "for col in label_cols :\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    label_X_val[col] = label_encoder.transform(X_val[col])\n",
    "\n",
    "    \n",
    "# Imputing on missing values \n",
    "my_imputer = SimpleImputer(strategy='median')\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(label_X_train))\n",
    "imputed_X_val = pd.DataFrame(my_imputer.transform(label_X_val))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = label_X_train.columns\n",
    "imputed_X_val.columns =label_X_val.columns\n",
    "\n",
    "\n",
    "# Getting MAE performance \n",
    "print(get_mae(X_train=imputed_X_train, y_train=y_train,\n",
    "                    X_val=imputed_X_val, y_val=y_val, model=model_3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 3 : One hot encoding values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17750.244041095888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "# Dropping categorical columns with empty data \n",
    "empty_categorical_cols = [col for col in object_cols if X_train[col].isnull().sum() > 0]\n",
    "reduced_X_train = X_train.drop(empty_categorical_cols, axis=1)\n",
    "reduced_X_val = X_val.drop(empty_categorical_cols, axis=1)\n",
    "\n",
    "final_obj_cols = list(set(object_cols) - set(empty_categorical_cols))\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(reduced_X_train[final_obj_cols]))\n",
    "OH_cols_val = pd.DataFrame(OH_encoder.transform(reduced_X_val[final_obj_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = reduced_X_train.index\n",
    "OH_cols_val.index = reduced_X_val.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_val = X_val.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_val = pd.concat([num_X_val, OH_cols_val], axis=1)\n",
    "\n",
    "# Imputing on missing data \n",
    "\n",
    "my_imputer = SimpleImputer(strategy='median')\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(OH_X_train))\n",
    "imputed_X_val = pd.DataFrame(my_imputer.transform(OH_X_val))\n",
    "\n",
    "# Getting MAE performance \n",
    "print(get_mae(X_train=imputed_X_train, y_train=y_train,\n",
    "                    X_val=imputed_X_val, y_val=y_val, model=model_3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "# Dropping categorical columns with empty data \n",
    "empty_categorical_cols = [col for col in object_cols if (X_train[col].isnull().sum() > 0) ]\n",
    "empty_categorical_cols += [col for col in object_cols if X_test[col].isnull().sum() > 0]\n",
    "reduced_X_train = X_train.drop(empty_categorical_cols, axis=1)\n",
    "reduced_X_test = X_test.drop(empty_categorical_cols, axis=1)\n",
    "final_obj_cols = list(set(object_cols) - set(empty_categorical_cols))\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(reduced_X_train[final_obj_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(reduced_X_test[final_obj_cols]))\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = reduced_X_train.index\n",
    "OH_cols_test.index = reduced_X_test.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_test = X_test.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "\n",
    "# Imputing on missing data \n",
    "my_imputer = SimpleImputer(strategy='median')\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(OH_X_train))\n",
    "imputed_X_test = pd.DataFrame(my_imputer.transform(OH_X_test))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = OH_X_train.columns\n",
    "imputed_X_test.columns = OH_X_test.columns\n",
    "imputed_X_test.index = OH_X_test.index\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_3.fit(imputed_X_train, y_train)\n",
    "\n",
    "# Generate test predictions\n",
    "preds_test = model_3.predict(imputed_X_test)\n",
    "\n",
    "# Save predictions in format used for competition scoring\n",
    "output = pd.DataFrame({'Id': imputed_X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_output(x) :\n",
    "    assert len(x) == 1459\n",
    "    assert all(output.Id == range(1461, 2920))\n",
    "    assert output.Id[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation 4 : Pipelines de preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input data \n",
    "X_full = pd.read_csv('Data/train.csv', sep=',', index_col='Id')\n",
    "X_test = pd.read_csv('Data/test.csv', sep=',', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "\n",
    "# Separate target from predictors\n",
    "y = X_full.SalePrice\n",
    "X = X_full.drop('SalePrice', axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8,\n",
    "                                                 test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying numerical and categorical data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_low_cardinality_cols = [col for col in X_train.columns if\n",
    "                                   ((X_train[col].dtype == 'object') and (X_train[col].nunique() <= 10))]\n",
    "\n",
    "categorical_high_cardinality_cols = [col for col in X_train.columns if\n",
    "                                   ((X_train[col].dtype == 'object') and (X_train[col].nunique() <= 10))]\n",
    "\n",
    "\n",
    "numerical_cols = [col for col in X_train.columns if\n",
    "                                   (X_train[col].dtype in ('int64', 'float64'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Defining transformers\n",
    "\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "categorical_low_cardinality_transformer = Pipeline(steps = [\n",
    "    ('imputer1', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))   \n",
    "])\n",
    "\n",
    "categorical_high_cardinality_transformer = Pipeline(steps = [\n",
    "    ('imputer2', SimpleImputer(strategy='most_frequent')),\n",
    "    ('labelencoding', LabelEncoder())   \n",
    "])\n",
    "\n",
    "\n",
    "# Bundle transformations for numerical and categorical features (using ColumnTransformer)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat_lc', categorical_low_cardinality_transformer, categorical_low_cardinality_cols)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML pipe definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  \n",
    "    ('model', model)  \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting results on validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 17651.196952054797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_val, preds)\n",
    "print('MAE:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Generate test predictions\n",
    "preds_test = my_pipeline.predict(X_test)\n",
    "\n",
    "# Save predictions in format used for competition scoring\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1459"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
